# ADR AI Self-Critique Rubric

## 개요

AI Self-Critique는 AI가 작성된 ADR을 분석하여 **품질을 객관적으로 평가**하고 구체적 개선 방안을 제시하는 과정이다.
이를 통해 설계 문서화 역량을 객관적으로 측정하고 시간에 따른 역량 성장을 추적할 수 있다.

---

## Red Team과의 분담

| 구분 | AI Self-Critique (Phase D) | Red Team |
|------|---------------------------|----------|
| 평가 대상 | "어떻게 작성했는가" (형식, 깊이, 완전성) | "무엇을 결정했는가" (내용) |
| 관점 | 역량 평가 (Context, 대안, Consequences 등) | 6관점 비평 (Security, Performance 등) |
| 결과 | 점수 (1-5점 × 5항목 = 25점) | 이슈 목록 (HIGH/MEDIUM/LOW) |
| 목적 | 설계 문서화 역량 측정 | 설계 결정 검증 |

---

## AI 평가 항목 (5개)

### 1. Context 충분성

**AI 평가 기준**: 비즈니스 요구사항, 기술 제약사항, 팀 상황이 구체적으로 명시되었는가?

| 점수 | 기준 | AI 평가 포인트 |
|------|------|----------------|
| 1점 | 배경 설명이 거의 없음 | Context 섹션이 비어있거나 한두 문장 |
| 2점 | 일부 배경만 설명됨 | 비즈니스 요구사항만 있고 기술 제약 누락 |
| 3점 | 기본적인 배경은 있으나 맥락 부족 | "왜 지금 결정해야 하는가"가 불명확 |
| 4점 | 대부분의 배경이 설명됨 | 일부 구체적 수치나 제약사항이 부족 |
| 5점 | 누가 읽어도 완전히 이해 가능 | 비즈니스/기술/팀 상황이 모두 구체적으로 명시 |

**AI 체크리스트**:
- [ ] 비즈니스 요구사항이 명시되어 있는가?
- [ ] 기술적 제약사항이 구체적으로 기술되어 있는가?
- [ ] 당시 팀/조직 상황이 설명되어 있는가?
- [ ] 왜 지금 결정해야 하는지 이유가 있는가?

---

### 2. 대안 분석 깊이

**AI 평가 기준**: 3개 이상 대안이 고려되었는가? 각 대안의 장단점이 구체적인가?

| 점수 | 기준 | AI 평가 포인트 |
|------|------|----------------|
| 1점 | 대안 없이 결정만 기술 | Alternatives 섹션 없음 |
| 2점 | 1개 대안만 형식적으로 언급 | "선택하지 않은 이유"가 없음 |
| 3점 | 2개 대안이 있으나 깊이 분석 안 됨 | 장단점이 모호하거나 일반적 |
| 4점 | 3개 이상 대안 분석, 일부 깊이 부족 | Trade-off Matrix가 불완전 |
| 5점 | 3개 이상 대안을 깊이 있게 분석 | Trade-off Matrix 완성, 각 대안의 실패 시나리오 포함 |

**AI 체크리스트**:
- [ ] 최소 3개 이상의 대안이 고려되었는가?
- [ ] 각 대안의 장단점이 구체적으로 분석되었는가?
- [ ] "선택하지 않은 이유"가 논리적인가?
- [ ] Trade-off Matrix가 작성되었는가?

---

### 3. Consequences 솔직성

**AI 평가 기준**: 부정적 결과, 위험, 위험 완화 전략이 포함되었는가?

| 점수 | 기준 | AI 평가 포인트 |
|------|------|----------------|
| 1점 | 긍정적 결과만 기술 | 부정적 결과 섹션 없음 |
| 2점 | 부정적 결과가 있으나 모호함 | "약간의 단점 있음" 정도 |
| 3점 | 일부 부정적 결과 포함, 위험은 누락 | 위험 완화 전략 없음 |
| 4점 | 부정적 결과와 위험 대부분 포함 | 일부 위험에 대한 완화 전략 누락 |
| 5점 | 긍정/부정/위험이 균형 있게 기술됨 | 각 위험에 대한 완화 전략 포함 |

**AI 체크리스트**:
- [ ] 부정적 결과가 구체적으로 기술되어 있는가?
- [ ] 잠재적 위험이 식별되어 있는가?
- [ ] 위험 완화 전략이 포함되어 있는가?
- [ ] "언제 이 결정이 틀릴 수 있는가"가 설명되어 있는가?

---

### 4. Reconsideration 구체성

**AI 평가 기준**: 정량적 임계값으로 재검토 조건이 명시되었는가?

| 점수 | 기준 | AI 평가 포인트 |
|------|------|----------------|
| 1점 | 재검토 조건 없음 | Reconsideration 섹션 없음 |
| 2점 | "필요 시 재검토" 등 모호한 조건 | 측정 불가능한 조건만 있음 |
| 3점 | 일부 조건이 있으나 측정 불가 | "트래픽 증가 시" 등 정성적 조건 |
| 4점 | 구체적 조건이 있으나 정량적이지 않음 | "사용자 많아지면" 정도 |
| 5점 | 정량적 임계값으로 재검토 조건 명시 | "DAU 10만 돌파 시", "응답시간 > 500ms 시" 등 |

**AI 체크리스트**:
- [ ] 재검토 트리거가 구체적인가?
- [ ] 정량적 임계값이 있는가? (예: "DAU 10만 돌파 시")
- [ ] 재검토 시점이 정의되어 있는가?
- [ ] 이 결정을 대체할 후속 ADR 계획이 있는가?

---

### 5. 설득력

**AI 평가 기준**: 결정의 논리적 근거가 명확한가? 예상 반론이 대응되었는가?

| 점수 | 기준 | AI 평가 포인트 |
|------|------|----------------|
| 1점 | 결정에 대한 근거 없음 | Decision 섹션에 "선택함"만 있음 |
| 2점 | 근거가 있으나 약함 | "일반적으로 많이 쓰임" 정도 |
| 3점 | 기본적 근거는 있으나 반론에 취약 | 구체적 데이터나 사례 부족 |
| 4점 | 타당한 근거, 일부 반론 대응 가능 | 예상 반론에 대한 대응이 불완전 |
| 5점 | 강력한 근거, 예상 반론까지 선제 대응 | 데이터, 사례, 반론 대응 모두 포함 |

**AI 체크리스트**:
- [ ] 결정의 논리적 근거가 명확한가?
- [ ] 예상되는 반대 의견이 무엇인가?
- [ ] 반대 의견에 대한 대응 논리가 있는가?
- [ ] 이해관계자의 우려사항이 다뤄졌는가?

---

## AI 평가 결과 형식

AI는 다음 형식으로 평가 결과를 출력한다:

```markdown
## AI Self-Critique 평가 결과

### 점수
| # | 항목 | 점수 (1~5) | AI 피드백 |
|---|------|------------|-----------|
| 1 | Context 충분성 | X/5 | [구체적 피드백: 무엇이 부족/우수한지] |
| 2 | 대안 분석 깊이 | X/5 | [구체적 피드백: 무엇이 부족/우수한지] |
| 3 | Consequences 솔직성 | X/5 | [구체적 피드백: 무엇이 부족/우수한지] |
| 4 | Reconsideration 구체성 | X/5 | [구체적 피드백: 무엇이 부족/우수한지] |
| 5 | 설득력 | X/5 | [구체적 피드백: 무엇이 부족/우수한지] |
| **총점** | | **XX/25** | |

### 등급 판정
- **등급**: [A/B/C/D/F]
- **판단**: [우수/양호/보완 필요/미흡/부족]

### 개선 제안
[점수가 낮은 항목별 구체적 개선 방안]

1. **[항목명]** (X/5점):
   - [구체적 개선 방안]
   - [예시]

2. **[항목명]** (X/5점):
   - [구체적 개선 방안]
   - [예시]
```

---

## 등급 기준 및 진행 가이드

| 총점 | 등급 | 판단 | 진행 가이드 |
|------|------|------|-------------|
| 22-25 | A | 우수 | `/redteam` 진행 |
| 18-21 | B | 양호 | `/redteam` 진행 |
| 14-17 | C | 보완 필요 | 수정 후 재평가 권장 |
| 10-13 | D | 미흡 | 수정 필요 |
| 5-9 | F | 부족 | 재작성 권장 |

---

## AI 평가 예시

### 예시: ADR-001 MySQL 선택

**입력 ADR 요약**:
- Context: 사용자 관리 시스템, 동시 사용자 1,000명, 응답 200ms, 트랜잭션 무결성
- Decision: MySQL 8.0
- Alternatives: PostgreSQL, MongoDB (2개만)
- Trade-off Matrix: 성능/확장성/팀 친숙도 기준
- Consequences: 긍정(팀 노하우, 안정성), 부정(수평확장 복잡도), 위험(DAU 50만 시 샤딩)
- Reconsideration: "DAU 500,000 시", "데이터 100GB 시"

**AI 평가 결과**:

```markdown
## AI Self-Critique 평가 결과

### 점수
| # | 항목 | 점수 | AI 피드백 |
|---|------|------|-----------|
| 1 | Context 충분성 | 4/5 | 비즈니스 요구사항과 기술 제약이 구체적. 팀 상황(MySQL 노하우)은 Trade-off에서 간접적으로 언급됨. |
| 2 | 대안 분석 깊이 | 3/5 | PostgreSQL, MongoDB만 고려. MariaDB, CockroachDB 등 다른 RDBMS 대안 누락. |
| 3 | Consequences 솔직성 | 5/5 | 긍정/부정/위험이 균형 있게 기술됨. 위험 완화 전략(샤딩)도 포함. |
| 4 | Reconsideration 구체성 | 4/5 | 정량적 임계값(DAU 500,000, 100GB)이 명시됨. 재검토 시점(정기 검토일)은 누락. |
| 5 | 설득력 | 4/5 | 팀 친숙도 근거가 타당. 총점이 낮은 대안(MySQL) 선택 이유가 논리적. 예상 반론에 대한 선제 대응은 약함. |
| **총점** | | **20/25** | |

### 등급 판정
- **등급**: B
- **판단**: 양호

### 개선 제안

1. **대안 분석 깊이** (3/5점):
   - MariaDB (MySQL 호환, 오픈소스), CockroachDB (분산 SQL) 등 대안 추가 고려
   - 예시: "CockroachDB: 수평 확장 용이하나 한국 커뮤니티 작음"

2. **Reconsideration 구체성** (4/5점):
   - 정기 재검토 일정 추가 (예: "6개월마다 재검토")
   - 후속 ADR 계획 명시 (예: "샤딩 필요 시 ADR-XXX 작성")
```

---

## 역량 추적

각 ADR의 Self-Critique 점수는 Episode에 저장되어 시간에 따른 역량 성장을 추적할 수 있다.

### Episode 역량 점수 섹션 예시

```markdown
## Competency Scores (역량 점수)

### ADR Self-Critique 점수
| ADR 번호 | Context | 대안분석 | Consequences | Reconsideration | 설득력 | 총점 | 등급 |
|----------|---------|----------|--------------|-----------------|--------|------|------|
| ADR-001 | 4/5 | 3/5 | 5/5 | 4/5 | 4/5 | 20/25 | B |

### 역량 성장 추세
| 일시 | 평균 점수 | 비고 |
|------|-----------|------|
| 2026-02-15 | 14/25 | 첫 ADR |
| 2026-02-21 | 20/25 | +6 향상 |
```

---

## 참조

- "The Art of Software Architecture" - Stephen T. Albin
- "Software Architecture in Practice" - Bass, Clements, Kazman
- Red Team 가이드: [../redteam/SKILL.md](../redteam/SKILL.md)
